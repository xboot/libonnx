/* Generated by the protocol buffer compiler.  DO NOT EDIT! */
/* Generated from: onnx.proto3 */

#ifndef PROTOBUF_C_onnx_2eproto3__INCLUDED
#define PROTOBUF_C_onnx_2eproto3__INCLUDED

#include "protobuf-c.h"

PROTOBUF_C__BEGIN_DECLS

#if PROTOBUF_C_VERSION_NUMBER < 1003000
# error This file was generated by a newer version of protoc-c which is incompatible with your libprotobuf-c headers. Please update your headers.
#elif 1004000 < PROTOBUF_C_MIN_COMPILER_VERSION
# error This file was generated by an older version of protoc-c which is incompatible with your libprotobuf-c headers. Please regenerate this file with a newer version of protoc-c.
#endif


typedef struct Onnx__AttributeProto Onnx__AttributeProto;
typedef struct Onnx__ValueInfoProto Onnx__ValueInfoProto;
typedef struct Onnx__NodeProto Onnx__NodeProto;
typedef struct Onnx__TrainingInfoProto Onnx__TrainingInfoProto;
typedef struct Onnx__ModelProto Onnx__ModelProto;
typedef struct Onnx__StringStringEntryProto Onnx__StringStringEntryProto;
typedef struct Onnx__TensorAnnotation Onnx__TensorAnnotation;
typedef struct Onnx__GraphProto Onnx__GraphProto;
typedef struct Onnx__TensorProto Onnx__TensorProto;
typedef struct Onnx__TensorProto__Segment Onnx__TensorProto__Segment;
typedef struct Onnx__SparseTensorProto Onnx__SparseTensorProto;
typedef struct Onnx__TensorShapeProto Onnx__TensorShapeProto;
typedef struct Onnx__TensorShapeProto__Dimension Onnx__TensorShapeProto__Dimension;
typedef struct Onnx__TypeProto Onnx__TypeProto;
typedef struct Onnx__TypeProto__Tensor Onnx__TypeProto__Tensor;
typedef struct Onnx__TypeProto__Sequence Onnx__TypeProto__Sequence;
typedef struct Onnx__TypeProto__Map Onnx__TypeProto__Map;
typedef struct Onnx__TypeProto__Optional Onnx__TypeProto__Optional;
typedef struct Onnx__TypeProto__SparseTensor Onnx__TypeProto__SparseTensor;
typedef struct Onnx__OperatorSetIdProto Onnx__OperatorSetIdProto;
typedef struct Onnx__FunctionProto Onnx__FunctionProto;


/* --- enums --- */

/*
 * Note: this enum is structurally identical to the OpSchema::AttrType
 * enum defined in schema.h.  If you rev one, you likely need to rev the other.
 */
typedef enum _Onnx__AttributeProto__AttributeType {
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__UNDEFINED = 0,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__FLOAT = 1,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__INT = 2,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__STRING = 3,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__TENSOR = 4,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__GRAPH = 5,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__SPARSE_TENSOR = 11,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__TYPE_PROTO = 13,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__FLOATS = 6,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__INTS = 7,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__STRINGS = 8,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__TENSORS = 9,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__GRAPHS = 10,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__SPARSE_TENSORS = 12,
  ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__TYPE_PROTOS = 14
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE)
} Onnx__AttributeProto__AttributeType;
typedef enum _Onnx__TensorProto__DataType {
  ONNX__TENSOR_PROTO__DATA_TYPE__UNDEFINED = 0,
  /*
   * Basic types.
   */
  /*
   * float
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT = 1,
  /*
   * uint8_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__UINT8 = 2,
  /*
   * int8_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__INT8 = 3,
  /*
   * uint16_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__UINT16 = 4,
  /*
   * int16_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__INT16 = 5,
  /*
   * int32_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__INT32 = 6,
  /*
   * int64_t
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__INT64 = 7,
  /*
   * string
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__STRING = 8,
  /*
   * bool
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__BOOL = 9,
  /*
   * IEEE754 half-precision floating-point format (16 bits wide).
   * This format has 1 sign bit, 5 exponent bits, and 10 mantissa bits.
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16 = 10,
  ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE = 11,
  ONNX__TENSOR_PROTO__DATA_TYPE__UINT32 = 12,
  ONNX__TENSOR_PROTO__DATA_TYPE__UINT64 = 13,
  /*
   * complex with float32 real and imaginary components
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__COMPLEX64 = 14,
  /*
   * complex with float64 real and imaginary components
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__COMPLEX128 = 15,
  /*
   * Non-IEEE floating-point format based on IEEE754 single-precision
   * floating-point number truncated to 16 bits.
   * This format has 1 sign bit, 8 exponent bits, and 7 mantissa bits.
   */
  ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16 = 16
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__TENSOR_PROTO__DATA_TYPE)
} Onnx__TensorProto__DataType;
/*
 * Location of the data for this tensor. MUST be one of:
 * - DEFAULT - data stored inside the protobuf message. Data is stored in raw_data (if set) otherwise in type-specified field.
 * - EXTERNAL - data stored in an external location as described by external_data field.
 */
typedef enum _Onnx__TensorProto__DataLocation {
  ONNX__TENSOR_PROTO__DATA_LOCATION__DEFAULT = 0,
  ONNX__TENSOR_PROTO__DATA_LOCATION__EXTERNAL = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__TENSOR_PROTO__DATA_LOCATION)
} Onnx__TensorProto__DataLocation;
/*
 * Versioning
 * ONNX versioning is specified in docs/IR.md and elaborated on in docs/Versioning.md
 * To be compatible with both proto2 and proto3, we will use a version number
 * that is not defined by the default value but an explicit enum number.
 */
typedef enum _Onnx__Version {
  /*
   * proto3 requires the first enum value to be zero.
   * We add this just to appease the compiler.
   */
  ONNX__VERSION___START_VERSION = 0,
  /*
   * The version field is always serialized and we will use it to store the
   * version that the  graph is generated from. This helps us set up version
   * control.
   * For the IR, we are using simple numbers starting with 0x00000001,
   * which was the version we published on Oct 10, 2017.
   */
  ONNX__VERSION__IR_VERSION_2017_10_10 = 1,
  /*
   * IR_VERSION 2 published on Oct 30, 2017
   * - Added type discriminator to AttributeProto to support proto3 users
   */
  ONNX__VERSION__IR_VERSION_2017_10_30 = 2,
  /*
   * IR VERSION 3 published on Nov 3, 2017
   * - For operator versioning:
   *    - Added new message OperatorSetIdProto
   *    - Added opset_import in ModelProto
   * - For vendor extensions, added domain in NodeProto
   */
  ONNX__VERSION__IR_VERSION_2017_11_3 = 3,
  /*
   * IR VERSION 4 published on Jan 22, 2019
   * - Relax constraint that initializers should be a subset of graph inputs
   * - Add type BFLOAT16
   */
  ONNX__VERSION__IR_VERSION_2019_1_22 = 4,
  /*
   * IR VERSION 5 published on March 18, 2019
   * - Add message TensorAnnotation.
   * - Add quantization annotation in GraphProto to map tensor with its scale and zero point quantization parameters.
   */
  ONNX__VERSION__IR_VERSION_2019_3_18 = 5,
  /*
   * IR VERSION 6 published on Sep 19, 2019
   * - Add support for sparse tensor constants stored in model.
   *   - Add message SparseTensorProto
   *   - Add sparse initializers
   */
  ONNX__VERSION__IR_VERSION_2019_9_19 = 6,
  /*
   * IR VERSION 7 published on May 8, 2020
   * - Add support to allow function body graph to rely on multiple external opreator sets.
   * - Add a list to promote inference graph's initializers to global and
   *   mutable variables. Global variables are visible in all graphs of the
   *   stored models.
   * - Add message TrainingInfoProto to store initialization
   *   method and training algorithm. The execution of TrainingInfoProto
   *   can modify the values of mutable variables.
   * - Implicitly add inference graph into each TrainingInfoProto's algorithm.
   */
  ONNX__VERSION__IR_VERSION_2020_5_8 = 7,
  /*
   * IR VERSION 8 published on <TBD>
   * Introduce TypeProto.SparseTensor
   * Introduce TypeProto.Optional
   * Added a list of FunctionProtos local to the model
   * Deprecated since_version and operator status from FunctionProto
   */
  ONNX__VERSION__IR_VERSION = 8
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__VERSION)
} Onnx__Version;
/*
 * Operator/function status.
 */
typedef enum _Onnx__OperatorStatus {
  ONNX__OPERATOR_STATUS__EXPERIMENTAL = 0,
  ONNX__OPERATOR_STATUS__STABLE = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__OPERATOR_STATUS)
} Onnx__OperatorStatus;

/* --- messages --- */

/*
 * Attributes
 * A named attribute containing either singular float, integer, string, graph,
 * and tensor values, or repeated float, integer, string, graph, and tensor values.
 * An AttributeProto MUST contain the name field, and *only one* of the
 * following content fields, effectively enforcing a C/C++ union equivalent.
 */
struct  Onnx__AttributeProto
{
  ProtobufCMessage base;
  /*
   * The name field MUST be present for this version of the IR.
   */
  /*
   * namespace Attribute
   */
  char *name;
  /*
   * if ref_attr_name is not empty, ref_attr_name is the attribute name in parent function.
   * In this case, this AttributeProto does not contain data, and it's a reference of attribute
   * in parent scope.
   * NOTE: This should ONLY be used in function (sub-graph). It's invalid to be used in main graph.
   */
  char *ref_attr_name;
  /*
   * A human-readable documentation for this attribute. Markdown is allowed.
   */
  char *doc_string;
  /*
   * The type field MUST be present for this version of the IR.
   * For 0.0.1 versions of the IR, this field was not defined, and
   * implementations needed to use has_field heuristics to determine
   * which value field was in use.  For IR_VERSION 0.0.2 or later, this
   * field MUST be set and match the f|i|s|t|... field in use.  This
   * change was made to accommodate proto3 implementations.
   */
  /*
   * discriminator that indicates which field below is in use
   */
  Onnx__AttributeProto__AttributeType type;
  /*
   * Exactly ONE of the following fields must be present for this version of the IR
   */
  /*
   * float
   */
  float f;
  /*
   * int
   */
  int64_t i;
  /*
   * UTF-8 string
   */
  ProtobufCBinaryData s;
  /*
   * tensor value
   */
  Onnx__TensorProto *t;
  /*
   * graph
   */
  Onnx__GraphProto *g;
  /*
   * sparse tensor value
   */
  Onnx__SparseTensorProto *sparse_tensor;
  /*
   * Do not use field below, it's deprecated.
   * optional ValueProto v = 12;         // value - subsumes everything but graph
   */
  /*
   * type proto
   */
  Onnx__TypeProto *tp;
  /*
   * list of floats
   */
  size_t n_floats;
  float *floats;
  /*
   * list of ints
   */
  size_t n_ints;
  int64_t *ints;
  /*
   * list of UTF-8 strings
   */
  size_t n_strings;
  ProtobufCBinaryData *strings;
  /*
   * list of tensors
   */
  size_t n_tensors;
  Onnx__TensorProto **tensors;
  /*
   * list of graph
   */
  size_t n_graphs;
  Onnx__GraphProto **graphs;
  /*
   * list of sparse tensors
   */
  size_t n_sparse_tensors;
  Onnx__SparseTensorProto **sparse_tensors;
  /*
   * list of type protos
   */
  size_t n_type_protos;
  Onnx__TypeProto **type_protos;
};
#define ONNX__ATTRIBUTE_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__attribute_proto__descriptor) \
    , (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, ONNX__ATTRIBUTE_PROTO__ATTRIBUTE_TYPE__UNDEFINED, 0, 0, {0,NULL}, NULL, NULL, NULL, NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL }


/*
 * Defines information on value, including the name, the type, and
 * the shape of the value.
 */
struct  Onnx__ValueInfoProto
{
  ProtobufCMessage base;
  /*
   * This field MUST be present in this version of the IR.
   */
  /*
   * namespace Value
   */
  char *name;
  /*
   * This field MUST be present in this version of the IR for
   * inputs and outputs of the top-level graph.
   */
  Onnx__TypeProto *type;
  /*
   * A human-readable documentation for this value. Markdown is allowed.
   */
  char *doc_string;
};
#define ONNX__VALUE_INFO_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__value_info_proto__descriptor) \
    , (char *)protobuf_c_empty_string, NULL, (char *)protobuf_c_empty_string }


/*
 * Nodes
 * Computation graphs are made up of a DAG of nodes, which represent what is
 * commonly called a "layer" or "pipeline stage" in machine learning frameworks.
 * For example, it can be a node of type "Conv" that takes in an image, a filter
 * tensor and a bias tensor, and produces the convolved output.
 */
struct  Onnx__NodeProto
{
  ProtobufCMessage base;
  /*
   * namespace Value
   */
  size_t n_input;
  char **input;
  /*
   * namespace Value
   */
  size_t n_output;
  char **output;
  /*
   * An optional identifier for this node in a graph.
   * This field MAY be absent in ths version of the IR.
   */
  /*
   * namespace Node
   */
  char *name;
  /*
   * The symbolic identifier of the Operator to execute.
   */
  /*
   * namespace Operator
   */
  char *op_type;
  /*
   * The domain of the OperatorSet that specifies the operator named by op_type.
   */
  /*
   * namespace Domain
   */
  char *domain;
  /*
   * Additional named attributes.
   */
  size_t n_attribute;
  Onnx__AttributeProto **attribute;
  /*
   * A human-readable documentation for this node. Markdown is allowed.
   */
  char *doc_string;
};
#define ONNX__NODE_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__node_proto__descriptor) \
    , 0,NULL, 0,NULL, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, 0,NULL, (char *)protobuf_c_empty_string }


/*
 * Training information
 * TrainingInfoProto stores information for training a model.
 * In particular, this defines two functionalities: an initialization-step
 * and a training-algorithm-step. Initialization resets the model
 * back to its original state as if no training has been performed.
 * Training algorithm improves the model based on input data.
 * The semantics of the initialization-step is that the initializers
 * in ModelProto.graph and in TrainingInfoProto.algorithm are first
 * initialized as specified by the initializers in the graph, and then
 * updated by the "initialization_binding" in every instance in
 * ModelProto.training_info.
 * The field "algorithm" defines a computation graph which represents a
 * training algorithm's step. After the execution of a
 * TrainingInfoProto.algorithm, the initializers specified by "update_binding"
 * may be immediately updated. If the targeted training algorithm contains
 * consecutive update steps (such as block coordinate descent methods),
 * the user needs to create a TrainingInfoProto for each step.
 */
struct  Onnx__TrainingInfoProto
{
  ProtobufCMessage base;
  /*
   * This field describes a graph to compute the initial tensors
   * upon starting the training process. Initialization graph has no input
   * and can have multiple outputs. Usually, trainable tensors in neural
   * networks are randomly initialized. To achieve that, for each tensor,
   * the user can put a random number operator such as RandomNormal or
   * RandomUniform in TrainingInfoProto.initialization.node and assign its
   * random output to the specific tensor using "initialization_binding".
   * This graph can also set the initializers in "algorithm" in the same
   * TrainingInfoProto; a use case is resetting the number of training
   * iteration to zero.
   * By default, this field is an empty graph and its evaluation does not
   * produce any output. Thus, no initializer would be changed by default.
   */
  Onnx__GraphProto *initialization;
  /*
   * This field represents a training algorithm step. Given required inputs,
   * it computes outputs to update initializers in its own or inference graph's
   * initializer lists. In general, this field contains loss node, gradient node,
   * optimizer node, increment of iteration count.
   * An execution of the training algorithm step is performed by executing the
   * graph obtained by combining the inference graph (namely "ModelProto.graph")
   * and the "algorithm" graph. That is, the actual the actual
   * input/initializer/output/node/value_info/sparse_initializer list of
   * the training graph is the concatenation of
   * "ModelProto.graph.input/initializer/output/node/value_info/sparse_initializer"
   * and "algorithm.input/initializer/output/node/value_info/sparse_initializer"
   * in that order. This combined graph must satisfy the normal ONNX conditions.
   * Now, let's provide a visualization of graph combination for clarity.
   * Let the inference graph (i.e., "ModelProto.graph") be
   *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d
   * and the "algorithm" graph be
   *    tensor_d -> Add -> tensor_e
   * The combination process results
   *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d -> Add -> tensor_e
   * Notice that an input of a node in the "algorithm" graph may reference the
   * output of a node in the inference graph (but not the other way round). Also, inference
   * node cannot reference inputs of "algorithm". With these restrictions, inference graph
   * can always be run independently without training information.
   * By default, this field is an empty graph and its evaluation does not
   * produce any output. Evaluating the default training step never
   * update any initializers.
   */
  Onnx__GraphProto *algorithm;
  /*
   * This field specifies the bindings from the outputs of "initialization" to
   * some initializers in "ModelProto.graph.initializer" and
   * the "algorithm.initializer" in the same TrainingInfoProto.
   * See "update_binding" below for details.
   * By default, this field is empty and no initializer would be changed
   * by the execution of "initialization".
   */
  size_t n_initialization_binding;
  Onnx__StringStringEntryProto **initialization_binding;
  /*
   * Gradient-based training is usually an iterative procedure. In one gradient
   * descent iteration, we apply
   * x = x - r * g
   * where "x" is the optimized tensor, "r" stands for learning rate, and "g" is
   * gradient of "x" with respect to a chosen loss. To avoid adding assignments
   * into the training graph, we split the update equation into
   * y = x - r * g
   * x = y
   * The user needs to save "y = x - r * g" into TrainingInfoProto.algorithm. To
   * tell that "y" should be assigned to "x", the field "update_binding" may
   * contain a key-value pair of strings, "x" (key of StringStringEntryProto)
   * and "y" (value of StringStringEntryProto).
   * For a neural network with multiple trainable (mutable) tensors, there can
   * be multiple key-value pairs in "update_binding".
   * The initializers appears as keys in "update_binding" are considered
   * mutable variables. This implies some behaviors
   * as described below.
   *  1. We have only unique keys in all "update_binding"s so that two
   *     variables may not have the same name. This ensures that one
   *     variable is assigned up to once.
   *  2. The keys must appear in names of "ModelProto.graph.initializer" or
   *     "TrainingInfoProto.algorithm.initializer".
   *  3. The values must be output names of "algorithm" or "ModelProto.graph.output".
   *  4. Mutable variables are initialized to the value specified by the
   *     corresponding initializer, and then potentially updated by
   *     "initializer_binding"s and "update_binding"s in "TrainingInfoProto"s.
   * This field usually contains names of trainable tensors
   * (in ModelProto.graph), optimizer states such as momentums in advanced
   * stochastic gradient methods (in TrainingInfoProto.graph),
   * and number of training iterations (in TrainingInfoProto.graph).
   * By default, this field is empty and no initializer would be changed
   * by the execution of "algorithm".
   */
  size_t n_update_binding;
  Onnx__StringStringEntryProto **update_binding;
};
#define ONNX__TRAINING_INFO_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__training_info_proto__descriptor) \
    , NULL, NULL, 0,NULL, 0,NULL }


/*
 * Models
 * ModelProto is a top-level file/container format for bundling a ML model and
 * associating its computation graph with metadata.
 * The semantics of the model are described by the associated GraphProto's.
 */
struct  Onnx__ModelProto
{
  ProtobufCMessage base;
  /*
   * The version of the IR this model targets. See Version enum above.
   * This field MUST be present.
   */
  int64_t ir_version;
  /*
   * The OperatorSets this model relies on.
   * All ModelProtos MUST have at least one entry that
   * specifies which version of the ONNX OperatorSet is
   * being imported.
   * All nodes in the ModelProto's graph will bind against the operator
   * with the same-domain/same-op_type operator with the HIGHEST version
   * in the referenced operator sets.
   */
  size_t n_opset_import;
  Onnx__OperatorSetIdProto **opset_import;
  /*
   * The name of the framework or tool used to generate this model.
   * This field SHOULD be present to indicate which implementation/tool/framework
   * emitted the model.
   */
  char *producer_name;
  /*
   * The version of the framework or tool used to generate this model.
   * This field SHOULD be present to indicate which implementation/tool/framework
   * emitted the model.
   */
  char *producer_version;
  /*
   * Domain name of the model.
   * We use reverse domain names as name space indicators. For example:
   * `com.facebook.fair` or `com.microsoft.cognitiveservices`
   * Together with `model_version` and GraphProto.name, this forms the unique identity of
   * the graph.
   */
  char *domain;
  /*
   * The version of the graph encoded. See Version enum below.
   */
  int64_t model_version;
  /*
   * A human-readable documentation for this model. Markdown is allowed.
   */
  char *doc_string;
  /*
   * The parameterized graph that is evaluated to execute the model.
   */
  Onnx__GraphProto *graph;
  /*
   * Named metadata values; keys should be distinct.
   */
  size_t n_metadata_props;
  Onnx__StringStringEntryProto **metadata_props;
  /*
   * Training-specific information. Sequentially executing all stored
   * `TrainingInfoProto.algorithm`s and assigning their outputs following
   * the corresponding `TrainingInfoProto.update_binding`s is one training
   * iteration. Similarly, to initialize the model
   * (as if training hasn't happened), the user should sequentially execute
   * all stored `TrainingInfoProto.initialization`s and assigns their outputs
   * using `TrainingInfoProto.initialization_binding`s.
   * If this field is empty, the training behavior of the model is undefined.
   */
  size_t n_training_info;
  Onnx__TrainingInfoProto **training_info;
  /*
   * A list of function protos local to the model.
   * Name of the function "FunctionProto.name" should be unique within the domain "FunctionProto.domain".
   * In case of any conflicts the behavior (whether the model local functions are given higher priority,
   * or standard opserator sets are given higher priotity or this is treated as error) is defined by 
   * the runtimes.
   * 
   * The operator sets imported by FunctionProto should be compatible with the ones
   * imported by ModelProto and other model local FunctionProtos. 
   * Example, if same operator set say 'A' is imported by a FunctionProto and ModelProto 
   * or by 2 FunctionProtos then versions for the operator set may be different but, 
   * the operator schema returned for op_type, domain, version combination
   * for both the versions should be same for every node in the function body.
   * One FunctionProto can reference other FunctionProto in the model, however, recursive reference
   * is not allowed.
   */
  size_t n_functions;
  Onnx__FunctionProto **functions;
};
#define ONNX__MODEL_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__model_proto__descriptor) \
    , 0, 0,NULL, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, 0, (char *)protobuf_c_empty_string, NULL, 0,NULL, 0,NULL, 0,NULL }


/*
 * StringStringEntryProto follows the pattern for cross-proto-version maps.
 * See https://developers.google.com/protocol-buffers/docs/proto3#maps
 */
struct  Onnx__StringStringEntryProto
{
  ProtobufCMessage base;
  char *key;
  char *value;
};
#define ONNX__STRING_STRING_ENTRY_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__string_string_entry_proto__descriptor) \
    , (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string }


struct  Onnx__TensorAnnotation
{
  ProtobufCMessage base;
  char *tensor_name;
  /*
   * <key, value> pairs to annotate tensor specified by <tensor_name> above.
   * The keys used in the mapping below must be pre-defined in ONNX spec.
   * For example, for 8-bit linear quantization case, 'SCALE_TENSOR', 'ZERO_POINT_TENSOR' will be pre-defined as
   * quantization parameter keys.
   */
  size_t n_quant_parameter_tensor_names;
  Onnx__StringStringEntryProto **quant_parameter_tensor_names;
};
#define ONNX__TENSOR_ANNOTATION__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__tensor_annotation__descriptor) \
    , (char *)protobuf_c_empty_string, 0,NULL }


/*
 * Graphs
 * A graph defines the computational logic of a model and is comprised of a parameterized
 * list of nodes that form a directed acyclic graph based on their inputs and outputs.
 * This is the equivalent of the "network" or "graph" in many deep learning
 * frameworks.
 */
struct  Onnx__GraphProto
{
  ProtobufCMessage base;
  /*
   * The nodes in the graph, sorted topologically.
   */
  size_t n_node;
  Onnx__NodeProto **node;
  /*
   * The name of the graph.
   */
  /*
   * namespace Graph
   */
  char *name;
  /*
   * A list of named tensor values, used to specify constant inputs of the graph.
   * Each initializer (both TensorProto as well SparseTensorProto) MUST have a name.
   * The name MUST be unique across both initializer and sparse_initializer,
   * but the name MAY also appear in the input list.
   */
  size_t n_initializer;
  Onnx__TensorProto **initializer;
  /*
   * Initializers (see above) stored in sparse format.
   */
  size_t n_sparse_initializer;
  Onnx__SparseTensorProto **sparse_initializer;
  /*
   * A human-readable documentation for this graph. Markdown is allowed.
   */
  char *doc_string;
  /*
   * The inputs and outputs of the graph.
   */
  size_t n_input;
  Onnx__ValueInfoProto **input;
  size_t n_output;
  Onnx__ValueInfoProto **output;
  /*
   * Information for the values in the graph. The ValueInfoProto.name's
   * must be distinct. It is optional for a value to appear in value_info list.
   */
  size_t n_value_info;
  Onnx__ValueInfoProto **value_info;
  /*
   * This field carries information to indicate the mapping among a tensor and its
   * quantization parameter tensors. For example:
   * For tensor 'a', it may have {'SCALE_TENSOR', 'a_scale'} and {'ZERO_POINT_TENSOR', 'a_zero_point'} annotated,
   * which means, tensor 'a_scale' and tensor 'a_zero_point' are scale and zero point of tensor 'a' in the model.
   */
  size_t n_quantization_annotation;
  Onnx__TensorAnnotation **quantization_annotation;
};
#define ONNX__GRAPH_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__graph_proto__descriptor) \
    , 0,NULL, (char *)protobuf_c_empty_string, 0,NULL, 0,NULL, (char *)protobuf_c_empty_string, 0,NULL, 0,NULL, 0,NULL, 0,NULL }


/*
 * For very large tensors, we may want to store them in chunks, in which
 * case the following fields will specify the segment that is stored in
 * the current TensorProto.
 */
struct  Onnx__TensorProto__Segment
{
  ProtobufCMessage base;
  int64_t begin;
  int64_t end;
};
#define ONNX__TENSOR_PROTO__SEGMENT__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__tensor_proto__segment__descriptor) \
    , 0, 0 }


/*
 * Tensors
 * A serialized tensor value.
 */
struct  Onnx__TensorProto
{
  ProtobufCMessage base;
  /*
   * The shape of the tensor.
   */
  size_t n_dims;
  int64_t *dims;
  /*
   * The data type of the tensor.
   * This field MUST have a valid TensorProto.DataType value
   */
  int32_t data_type;
  Onnx__TensorProto__Segment *segment;
  /*
   * For float and complex64 values
   * Complex64 tensors are encoded as a single array of floats,
   * with the real components appearing in odd numbered positions,
   * and the corresponding imaginary component appearing in the
   * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
   * is encoded as [1.0, 2.0 ,3.0 ,4.0]
   * When this field is present, the data_type field MUST be FLOAT or COMPLEX64.
   */
  size_t n_float_data;
  float *float_data;
  /*
   * For int32, uint8, int8, uint16, int16, bool, and float16 values
   * float16 values must be bit-wise converted to an uint16_t prior
   * to writing to the buffer.
   * When this field is present, the data_type field MUST be
   * INT32, INT16, INT8, UINT16, UINT8, BOOL, or FLOAT16
   */
  size_t n_int32_data;
  int32_t *int32_data;
  /*
   * For strings.
   * Each element of string_data is a UTF-8 encoded Unicode
   * string. No trailing null, no leading BOM. The protobuf "string"
   * scalar type is not used to match ML community conventions.
   * When this field is present, the data_type field MUST be STRING
   */
  size_t n_string_data;
  ProtobufCBinaryData *string_data;
  /*
   * For int64.
   * When this field is present, the data_type field MUST be INT64
   */
  size_t n_int64_data;
  int64_t *int64_data;
  /*
   * Optionally, a name for the tensor.
   */
  /*
   * namespace Value
   */
  char *name;
  /*
   * A human-readable documentation for this tensor. Markdown is allowed.
   */
  char *doc_string;
  /*
   * Serializations can either use one of the fields above, or use this
   * raw bytes field. The only exception is the string case, where one is
   * required to store the content in the repeated bytes string_data field.
   * When this raw_data field is used to store tensor value, elements MUST
   * be stored in as fixed-width, little-endian order.
   * Floating-point data types MUST be stored in IEEE 754 format.
   * Complex64 elements must be written as two consecutive FLOAT values, real component first.
   * Complex128 elements must be written as two consecutive DOUBLE values, real component first.
   * Boolean type MUST be written one byte per tensor element (00000001 for true, 00000000 for false).
   * Note: the advantage of specific field rather than the raw_data field is
   * that in some cases (e.g. int data), protobuf does a better packing via
   * variable length storage, and may lead to smaller binary footprint.
   * When this field is present, the data_type field MUST NOT be STRING or UNDEFINED
   */
  ProtobufCBinaryData raw_data;
  /*
   * Data can be stored inside the protobuf file using type-specific fields or raw_data.
   * Alternatively, raw bytes data can be stored in an external file, using the external_data field.
   * external_data stores key-value pairs describing data location. Recognized keys are:
   * - "location" (required) - POSIX filesystem path relative to the directory where the ONNX
   *                           protobuf model was stored
   * - "offset" (optional) - position of byte at which stored data begins. Integer stored as string.
   *                         Offset values SHOULD be multiples 4096 (page size) to enable mmap support.
   * - "length" (optional) - number of bytes containing data. Integer stored as string.
   * - "checksum" (optional) - SHA1 digest of file specified in under 'location' key.
   */
  size_t n_external_data;
  Onnx__StringStringEntryProto **external_data;
  /*
   * If value not set, data is stored in raw_data (if set) otherwise in type-specified field.
   */
  Onnx__TensorProto__DataLocation data_location;
  /*
   * For double
   * Complex128 tensors are encoded as a single array of doubles,
   * with the real components appearing in odd numbered positions,
   * and the corresponding imaginary component appearing in the
   * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
   * is encoded as [1.0, 2.0 ,3.0 ,4.0]
   * When this field is present, the data_type field MUST be DOUBLE or COMPLEX128
   */
  size_t n_double_data;
  double *double_data;
  /*
   * For uint64 and uint32 values
   * When this field is present, the data_type field MUST be
   * UINT32 or UINT64
   */
  size_t n_uint64_data;
  uint64_t *uint64_data;
};
#define ONNX__TENSOR_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__tensor_proto__descriptor) \
    , 0,NULL, 0, NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL, (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string, {0,NULL}, 0,NULL, ONNX__TENSOR_PROTO__DATA_LOCATION__DEFAULT, 0,NULL, 0,NULL }


/*
 * A serialized sparse-tensor value
 */
struct  Onnx__SparseTensorProto
{
  ProtobufCMessage base;
  /*
   * The sequence of non-default values are encoded as a tensor of shape [NNZ].
   * The default-value is zero for numeric tensors, and empty-string for string tensors.
   * values must have a non-empty name present which serves as a name for SparseTensorProto
   * when used in sparse_initializer list.
   */
  Onnx__TensorProto *values;
  /*
   * The indices of the non-default values, which may be stored in one of two formats.
   * (a) Indices can be a tensor of shape [NNZ, rank] with the [i,j]-th value
   * corresponding to the j-th index of the i-th value (in the values tensor).
   * (b) Indices can be a tensor of shape [NNZ], in which case the i-th value
   * must be the linearized-index of the i-th value (in the values tensor).
   * The linearized-index can be converted into an index tuple (k_1,...,k_rank)
   * using the shape provided below.
   * The indices must appear in ascending order without duplication.
   * In the first format, the ordering is lexicographic-ordering:
   * e.g., index-value [1,4] must appear before [2,1]
   */
  Onnx__TensorProto *indices;
  /*
   * The shape of the underlying dense-tensor: [dim_1, dim_2, ... dim_rank]
   */
  size_t n_dims;
  int64_t *dims;
};
#define ONNX__SPARSE_TENSOR_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__sparse_tensor_proto__descriptor) \
    , NULL, NULL, 0,NULL }


typedef enum {
  ONNX__TENSOR_SHAPE_PROTO__DIMENSION__VALUE__NOT_SET = 0,
  ONNX__TENSOR_SHAPE_PROTO__DIMENSION__VALUE_DIM_VALUE = 1,
  ONNX__TENSOR_SHAPE_PROTO__DIMENSION__VALUE_DIM_PARAM = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__TENSOR_SHAPE_PROTO__DIMENSION__VALUE__CASE)
} Onnx__TensorShapeProto__Dimension__ValueCase;

struct  Onnx__TensorShapeProto__Dimension
{
  ProtobufCMessage base;
  /*
   * Standard denotation can optionally be used to denote tensor
   * dimensions with standard semantic descriptions to ensure
   * that operations are applied to the correct axis of a tensor.
   * Refer to https://github.com/onnx/onnx/blob/main/docs/DimensionDenotation.md#denotation-definition
   * for pre-defined dimension denotations.
   */
  char *denotation;
  Onnx__TensorShapeProto__Dimension__ValueCase value_case;
  union {
    int64_t dim_value;
    /*
     * namespace Shape
     */
    char *dim_param;
  };
};
#define ONNX__TENSOR_SHAPE_PROTO__DIMENSION__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__tensor_shape_proto__dimension__descriptor) \
    , (char *)protobuf_c_empty_string, ONNX__TENSOR_SHAPE_PROTO__DIMENSION__VALUE__NOT_SET, {0} }


/*
 * Defines a tensor shape. A dimension can be either an integer value
 * or a symbolic variable. A symbolic variable represents an unknown
 * dimension.
 */
struct  Onnx__TensorShapeProto
{
  ProtobufCMessage base;
  size_t n_dim;
  Onnx__TensorShapeProto__Dimension **dim;
};
#define ONNX__TENSOR_SHAPE_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__tensor_shape_proto__descriptor) \
    , 0,NULL }


struct  Onnx__TypeProto__Tensor
{
  ProtobufCMessage base;
  /*
   * This field MUST NOT have the value of UNDEFINED
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   */
  int32_t elem_type;
  Onnx__TensorShapeProto *shape;
};
#define ONNX__TYPE_PROTO__TENSOR__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__tensor__descriptor) \
    , 0, NULL }


/*
 * repeated T
 */
struct  Onnx__TypeProto__Sequence
{
  ProtobufCMessage base;
  /*
   * The type and optional shape of each element of the sequence.
   * This field MUST be present for this version of the IR.
   */
  Onnx__TypeProto *elem_type;
};
#define ONNX__TYPE_PROTO__SEQUENCE__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__sequence__descriptor) \
    , NULL }


/*
 * map<K,V>
 */
struct  Onnx__TypeProto__Map
{
  ProtobufCMessage base;
  /*
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   * This field MUST refer to an integral type ([U]INT{8|16|32|64}) or STRING
   */
  int32_t key_type;
  /*
   * This field MUST be present for this version of the IR.
   */
  Onnx__TypeProto *value_type;
};
#define ONNX__TYPE_PROTO__MAP__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__map__descriptor) \
    , 0, NULL }


/*
 * wrapper for Tensor, Sequence, or Map
 */
struct  Onnx__TypeProto__Optional
{
  ProtobufCMessage base;
  /*
   * The type and optional shape of the element wrapped.
   * This field MUST be present for this version of the IR.
   * Possible values correspond to OptionalProto.DataType enum
   */
  Onnx__TypeProto *elem_type;
};
#define ONNX__TYPE_PROTO__OPTIONAL__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__optional__descriptor) \
    , NULL }


struct  Onnx__TypeProto__SparseTensor
{
  ProtobufCMessage base;
  /*
   * This field MUST NOT have the value of UNDEFINED
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   */
  int32_t elem_type;
  Onnx__TensorShapeProto *shape;
};
#define ONNX__TYPE_PROTO__SPARSE_TENSOR__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__sparse_tensor__descriptor) \
    , 0, NULL }


typedef enum {
  ONNX__TYPE_PROTO__VALUE__NOT_SET = 0,
  ONNX__TYPE_PROTO__VALUE_TENSOR_TYPE = 1,
  ONNX__TYPE_PROTO__VALUE_SEQUENCE_TYPE = 4,
  ONNX__TYPE_PROTO__VALUE_MAP_TYPE = 5,
  ONNX__TYPE_PROTO__VALUE_OPTIONAL_TYPE = 9,
  ONNX__TYPE_PROTO__VALUE_SPARSE_TENSOR_TYPE = 8
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(ONNX__TYPE_PROTO__VALUE__CASE)
} Onnx__TypeProto__ValueCase;

/*
 * Types
 * The standard ONNX data types.
 */
struct  Onnx__TypeProto
{
  ProtobufCMessage base;
  /*
   * An optional denotation can be used to denote the whole
   * type with a standard semantic description as to what is
   * stored inside. Refer to https://github.com/onnx/onnx/blob/main/docs/TypeDenotation.md#type-denotation-definition
   * for pre-defined type denotations.
   */
  char *denotation;
  Onnx__TypeProto__ValueCase value_case;
  union {
    /*
     * The type of a tensor.
     */
    Onnx__TypeProto__Tensor *tensor_type;
    /*
     * The type of a sequence.
     */
    Onnx__TypeProto__Sequence *sequence_type;
    /*
     * The type of a map.
     */
    Onnx__TypeProto__Map *map_type;
    /*
     * The type of an optional.
     */
    Onnx__TypeProto__Optional *optional_type;
    /*
     * Type of the sparse tensor
     */
    Onnx__TypeProto__SparseTensor *sparse_tensor_type;
  };
};
#define ONNX__TYPE_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__type_proto__descriptor) \
    , (char *)protobuf_c_empty_string, ONNX__TYPE_PROTO__VALUE__NOT_SET, {0} }


/*
 * Operator Sets
 * OperatorSets are uniquely identified by a (domain, opset_version) pair.
 */
struct  Onnx__OperatorSetIdProto
{
  ProtobufCMessage base;
  /*
   * The domain of the operator set being identified.
   * The empty string ("") or absence of this field implies the operator
   * set that is defined as part of the ONNX specification.
   * This field MUST be present in this version of the IR when referring to any other operator set.
   */
  char *domain;
  /*
   * The version of the operator set being identified.
   * This field MUST be present in this version of the IR.
   */
  int64_t version;
};
#define ONNX__OPERATOR_SET_ID_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__operator_set_id_proto__descriptor) \
    , (char *)protobuf_c_empty_string, 0 }


struct  Onnx__FunctionProto
{
  ProtobufCMessage base;
  /*
   * The name of the function, similar usage of op_type in OperatorProto.
   * Combined with FunctionProto.domain, this forms the unique identity of
   * the FunctionProto.
   */
  char *name;
  /*
   * The inputs and outputs of the function.
   */
  size_t n_input;
  char **input;
  size_t n_output;
  char **output;
  /*
   * The attributes of the function.
   */
  size_t n_attribute;
  char **attribute;
  /*
   * The nodes in the function.
   */
  size_t n_node;
  Onnx__NodeProto **node;
  /*
   * A human-readable documentation for this function. Markdown is allowed.
   */
  char *doc_string;
  size_t n_opset_import;
  Onnx__OperatorSetIdProto **opset_import;
  /*
   * The domain which this function belongs to. Combined with FunctionProto.name, this forms the unique identity of
   * the FunctionProto.
   */
  char *domain;
};
#define ONNX__FUNCTION_PROTO__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&onnx__function_proto__descriptor) \
    , (char *)protobuf_c_empty_string, 0,NULL, 0,NULL, 0,NULL, 0,NULL, (char *)protobuf_c_empty_string, 0,NULL, (char *)protobuf_c_empty_string }


/* Onnx__AttributeProto methods */
void   onnx__attribute_proto__init
                     (Onnx__AttributeProto         *message);
size_t onnx__attribute_proto__get_packed_size
                     (const Onnx__AttributeProto   *message);
size_t onnx__attribute_proto__pack
                     (const Onnx__AttributeProto   *message,
                      uint8_t             *out);
size_t onnx__attribute_proto__pack_to_buffer
                     (const Onnx__AttributeProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__AttributeProto *
       onnx__attribute_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__attribute_proto__free_unpacked
                     (Onnx__AttributeProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__ValueInfoProto methods */
void   onnx__value_info_proto__init
                     (Onnx__ValueInfoProto         *message);
size_t onnx__value_info_proto__get_packed_size
                     (const Onnx__ValueInfoProto   *message);
size_t onnx__value_info_proto__pack
                     (const Onnx__ValueInfoProto   *message,
                      uint8_t             *out);
size_t onnx__value_info_proto__pack_to_buffer
                     (const Onnx__ValueInfoProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__ValueInfoProto *
       onnx__value_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__value_info_proto__free_unpacked
                     (Onnx__ValueInfoProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__NodeProto methods */
void   onnx__node_proto__init
                     (Onnx__NodeProto         *message);
size_t onnx__node_proto__get_packed_size
                     (const Onnx__NodeProto   *message);
size_t onnx__node_proto__pack
                     (const Onnx__NodeProto   *message,
                      uint8_t             *out);
size_t onnx__node_proto__pack_to_buffer
                     (const Onnx__NodeProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__NodeProto *
       onnx__node_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__node_proto__free_unpacked
                     (Onnx__NodeProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__TrainingInfoProto methods */
void   onnx__training_info_proto__init
                     (Onnx__TrainingInfoProto         *message);
size_t onnx__training_info_proto__get_packed_size
                     (const Onnx__TrainingInfoProto   *message);
size_t onnx__training_info_proto__pack
                     (const Onnx__TrainingInfoProto   *message,
                      uint8_t             *out);
size_t onnx__training_info_proto__pack_to_buffer
                     (const Onnx__TrainingInfoProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__TrainingInfoProto *
       onnx__training_info_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__training_info_proto__free_unpacked
                     (Onnx__TrainingInfoProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__ModelProto methods */
void   onnx__model_proto__init
                     (Onnx__ModelProto         *message);
size_t onnx__model_proto__get_packed_size
                     (const Onnx__ModelProto   *message);
size_t onnx__model_proto__pack
                     (const Onnx__ModelProto   *message,
                      uint8_t             *out);
size_t onnx__model_proto__pack_to_buffer
                     (const Onnx__ModelProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__ModelProto *
       onnx__model_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__model_proto__free_unpacked
                     (Onnx__ModelProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__StringStringEntryProto methods */
void   onnx__string_string_entry_proto__init
                     (Onnx__StringStringEntryProto         *message);
size_t onnx__string_string_entry_proto__get_packed_size
                     (const Onnx__StringStringEntryProto   *message);
size_t onnx__string_string_entry_proto__pack
                     (const Onnx__StringStringEntryProto   *message,
                      uint8_t             *out);
size_t onnx__string_string_entry_proto__pack_to_buffer
                     (const Onnx__StringStringEntryProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__StringStringEntryProto *
       onnx__string_string_entry_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__string_string_entry_proto__free_unpacked
                     (Onnx__StringStringEntryProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__TensorAnnotation methods */
void   onnx__tensor_annotation__init
                     (Onnx__TensorAnnotation         *message);
size_t onnx__tensor_annotation__get_packed_size
                     (const Onnx__TensorAnnotation   *message);
size_t onnx__tensor_annotation__pack
                     (const Onnx__TensorAnnotation   *message,
                      uint8_t             *out);
size_t onnx__tensor_annotation__pack_to_buffer
                     (const Onnx__TensorAnnotation   *message,
                      ProtobufCBuffer     *buffer);
Onnx__TensorAnnotation *
       onnx__tensor_annotation__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__tensor_annotation__free_unpacked
                     (Onnx__TensorAnnotation *message,
                      ProtobufCAllocator *allocator);
/* Onnx__GraphProto methods */
void   onnx__graph_proto__init
                     (Onnx__GraphProto         *message);
size_t onnx__graph_proto__get_packed_size
                     (const Onnx__GraphProto   *message);
size_t onnx__graph_proto__pack
                     (const Onnx__GraphProto   *message,
                      uint8_t             *out);
size_t onnx__graph_proto__pack_to_buffer
                     (const Onnx__GraphProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__GraphProto *
       onnx__graph_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__graph_proto__free_unpacked
                     (Onnx__GraphProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__TensorProto__Segment methods */
void   onnx__tensor_proto__segment__init
                     (Onnx__TensorProto__Segment         *message);
/* Onnx__TensorProto methods */
void   onnx__tensor_proto__init
                     (Onnx__TensorProto         *message);
size_t onnx__tensor_proto__get_packed_size
                     (const Onnx__TensorProto   *message);
size_t onnx__tensor_proto__pack
                     (const Onnx__TensorProto   *message,
                      uint8_t             *out);
size_t onnx__tensor_proto__pack_to_buffer
                     (const Onnx__TensorProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__TensorProto *
       onnx__tensor_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__tensor_proto__free_unpacked
                     (Onnx__TensorProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__SparseTensorProto methods */
void   onnx__sparse_tensor_proto__init
                     (Onnx__SparseTensorProto         *message);
size_t onnx__sparse_tensor_proto__get_packed_size
                     (const Onnx__SparseTensorProto   *message);
size_t onnx__sparse_tensor_proto__pack
                     (const Onnx__SparseTensorProto   *message,
                      uint8_t             *out);
size_t onnx__sparse_tensor_proto__pack_to_buffer
                     (const Onnx__SparseTensorProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__SparseTensorProto *
       onnx__sparse_tensor_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__sparse_tensor_proto__free_unpacked
                     (Onnx__SparseTensorProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__TensorShapeProto__Dimension methods */
void   onnx__tensor_shape_proto__dimension__init
                     (Onnx__TensorShapeProto__Dimension         *message);
/* Onnx__TensorShapeProto methods */
void   onnx__tensor_shape_proto__init
                     (Onnx__TensorShapeProto         *message);
size_t onnx__tensor_shape_proto__get_packed_size
                     (const Onnx__TensorShapeProto   *message);
size_t onnx__tensor_shape_proto__pack
                     (const Onnx__TensorShapeProto   *message,
                      uint8_t             *out);
size_t onnx__tensor_shape_proto__pack_to_buffer
                     (const Onnx__TensorShapeProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__TensorShapeProto *
       onnx__tensor_shape_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__tensor_shape_proto__free_unpacked
                     (Onnx__TensorShapeProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__TypeProto__Tensor methods */
void   onnx__type_proto__tensor__init
                     (Onnx__TypeProto__Tensor         *message);
/* Onnx__TypeProto__Sequence methods */
void   onnx__type_proto__sequence__init
                     (Onnx__TypeProto__Sequence         *message);
/* Onnx__TypeProto__Map methods */
void   onnx__type_proto__map__init
                     (Onnx__TypeProto__Map         *message);
/* Onnx__TypeProto__Optional methods */
void   onnx__type_proto__optional__init
                     (Onnx__TypeProto__Optional         *message);
/* Onnx__TypeProto__SparseTensor methods */
void   onnx__type_proto__sparse_tensor__init
                     (Onnx__TypeProto__SparseTensor         *message);
/* Onnx__TypeProto methods */
void   onnx__type_proto__init
                     (Onnx__TypeProto         *message);
size_t onnx__type_proto__get_packed_size
                     (const Onnx__TypeProto   *message);
size_t onnx__type_proto__pack
                     (const Onnx__TypeProto   *message,
                      uint8_t             *out);
size_t onnx__type_proto__pack_to_buffer
                     (const Onnx__TypeProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__TypeProto *
       onnx__type_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__type_proto__free_unpacked
                     (Onnx__TypeProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__OperatorSetIdProto methods */
void   onnx__operator_set_id_proto__init
                     (Onnx__OperatorSetIdProto         *message);
size_t onnx__operator_set_id_proto__get_packed_size
                     (const Onnx__OperatorSetIdProto   *message);
size_t onnx__operator_set_id_proto__pack
                     (const Onnx__OperatorSetIdProto   *message,
                      uint8_t             *out);
size_t onnx__operator_set_id_proto__pack_to_buffer
                     (const Onnx__OperatorSetIdProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__OperatorSetIdProto *
       onnx__operator_set_id_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__operator_set_id_proto__free_unpacked
                     (Onnx__OperatorSetIdProto *message,
                      ProtobufCAllocator *allocator);
/* Onnx__FunctionProto methods */
void   onnx__function_proto__init
                     (Onnx__FunctionProto         *message);
size_t onnx__function_proto__get_packed_size
                     (const Onnx__FunctionProto   *message);
size_t onnx__function_proto__pack
                     (const Onnx__FunctionProto   *message,
                      uint8_t             *out);
size_t onnx__function_proto__pack_to_buffer
                     (const Onnx__FunctionProto   *message,
                      ProtobufCBuffer     *buffer);
Onnx__FunctionProto *
       onnx__function_proto__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   onnx__function_proto__free_unpacked
                     (Onnx__FunctionProto *message,
                      ProtobufCAllocator *allocator);
/* --- per-message closures --- */

typedef void (*Onnx__AttributeProto_Closure)
                 (const Onnx__AttributeProto *message,
                  void *closure_data);
typedef void (*Onnx__ValueInfoProto_Closure)
                 (const Onnx__ValueInfoProto *message,
                  void *closure_data);
typedef void (*Onnx__NodeProto_Closure)
                 (const Onnx__NodeProto *message,
                  void *closure_data);
typedef void (*Onnx__TrainingInfoProto_Closure)
                 (const Onnx__TrainingInfoProto *message,
                  void *closure_data);
typedef void (*Onnx__ModelProto_Closure)
                 (const Onnx__ModelProto *message,
                  void *closure_data);
typedef void (*Onnx__StringStringEntryProto_Closure)
                 (const Onnx__StringStringEntryProto *message,
                  void *closure_data);
typedef void (*Onnx__TensorAnnotation_Closure)
                 (const Onnx__TensorAnnotation *message,
                  void *closure_data);
typedef void (*Onnx__GraphProto_Closure)
                 (const Onnx__GraphProto *message,
                  void *closure_data);
typedef void (*Onnx__TensorProto__Segment_Closure)
                 (const Onnx__TensorProto__Segment *message,
                  void *closure_data);
typedef void (*Onnx__TensorProto_Closure)
                 (const Onnx__TensorProto *message,
                  void *closure_data);
typedef void (*Onnx__SparseTensorProto_Closure)
                 (const Onnx__SparseTensorProto *message,
                  void *closure_data);
typedef void (*Onnx__TensorShapeProto__Dimension_Closure)
                 (const Onnx__TensorShapeProto__Dimension *message,
                  void *closure_data);
typedef void (*Onnx__TensorShapeProto_Closure)
                 (const Onnx__TensorShapeProto *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto__Tensor_Closure)
                 (const Onnx__TypeProto__Tensor *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto__Sequence_Closure)
                 (const Onnx__TypeProto__Sequence *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto__Map_Closure)
                 (const Onnx__TypeProto__Map *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto__Optional_Closure)
                 (const Onnx__TypeProto__Optional *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto__SparseTensor_Closure)
                 (const Onnx__TypeProto__SparseTensor *message,
                  void *closure_data);
typedef void (*Onnx__TypeProto_Closure)
                 (const Onnx__TypeProto *message,
                  void *closure_data);
typedef void (*Onnx__OperatorSetIdProto_Closure)
                 (const Onnx__OperatorSetIdProto *message,
                  void *closure_data);
typedef void (*Onnx__FunctionProto_Closure)
                 (const Onnx__FunctionProto *message,
                  void *closure_data);

/* --- services --- */


/* --- descriptors --- */

extern const ProtobufCEnumDescriptor    onnx__version__descriptor;
extern const ProtobufCEnumDescriptor    onnx__operator_status__descriptor;
extern const ProtobufCMessageDescriptor onnx__attribute_proto__descriptor;
extern const ProtobufCEnumDescriptor    onnx__attribute_proto__attribute_type__descriptor;
extern const ProtobufCMessageDescriptor onnx__value_info_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__node_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__training_info_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__model_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__string_string_entry_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__tensor_annotation__descriptor;
extern const ProtobufCMessageDescriptor onnx__graph_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__tensor_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__tensor_proto__segment__descriptor;
extern const ProtobufCEnumDescriptor    onnx__tensor_proto__data_type__descriptor;
extern const ProtobufCEnumDescriptor    onnx__tensor_proto__data_location__descriptor;
extern const ProtobufCMessageDescriptor onnx__sparse_tensor_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__tensor_shape_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__tensor_shape_proto__dimension__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__tensor__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__sequence__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__map__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__optional__descriptor;
extern const ProtobufCMessageDescriptor onnx__type_proto__sparse_tensor__descriptor;
extern const ProtobufCMessageDescriptor onnx__operator_set_id_proto__descriptor;
extern const ProtobufCMessageDescriptor onnx__function_proto__descriptor;

PROTOBUF_C__END_DECLS


#endif  /* PROTOBUF_C_onnx_2eproto3__INCLUDED */
